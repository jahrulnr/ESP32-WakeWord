# MultiNet7 Custom Speech Commands Guide

This guide explains how to customize speech commands for MultiNet7 using the phonetic generator and command formatting system.

> **Based on**: [ESP-SR MultiNet7 Documentation](https://docs.espressif.com/projects/esp-sr/en/latest/esp32/speech_command_recognition/README.html#multinet7-customize-speech-commands)

## ðŸŽ¯ Overview

MultiNet7 uses **phonemes** for English speech commands, which provides more accurate recognition than grapheme-based systems. This project includes tools to automatically generate phonetic representations from text commands.

### Key Features
- Support for up to **200 custom commands**
- **Phoneme-based recognition** for higher accuracy
- **Real-time command modification** via API
- **Automated phonetic conversion** using G2P (Grapheme-to-Phoneme)
- **Low latency** (<500ms recognition time)

## ðŸ—ï¸ Architecture

```
Text Commands â†’ G2P Conversion â†’ Phoneme Commands â†’ MultiNet7 Model
     â†“               â†“                  â†“              â†“
"turn on light" â†’ TkN eN Lim â†’ Model Training â†’ ESP32 Recognition
```

## ðŸ“ File Structure

```
model/
â”œâ”€â”€ multinet_g2p.py           # Phonetic generator tool
â”œâ”€â”€ requirements.txt          # Python dependencies (pandas, g2p_en)
â”œâ”€â”€ customize_speech_commands.md  # This guide
â”œâ”€â”€ multinet_model/
â”‚   â””â”€â”€ fst/
â”‚       â””â”€â”€ commands_en.txt   # Command definitions file
â””â”€â”€ target/                   # Built models
    â”œâ”€â”€ mn6_en/              # MultiNet6 English model
    â”œâ”€â”€ mn7_cn/              # MultiNet7 Chinese model  
    â””â”€â”€ fst/                 # Finite State Transducer files
```

## ðŸ› ï¸ Setup

### 1. Install Dependencies

```bash
cd /apps/PlatformIO/WakeWord/model
pip3 install -r requirements.txt
```

This installs:
- `pandas` - Data manipulation for command processing
- `g2p_en` - English Grapheme-to-Phoneme conversion

### 2. Download NLTK Data

The G2P tool requires NLTK POS tagger data:

```bash
python3 -c "import nltk; nltk.download('averaged_perceptron_tagger_eng')"
```

## ðŸ“ Command Format

MultiNet7 uses a CSV format in `multinet_model/fst/commands_en.txt`:

```csv
# command_id,command_grapheme,command_phoneme
1,tell me a joke,TfL Mm c qbK
2,sing a song,Sgl c Sel
3,turn on light,TkN eN Lim
4,play music,PLf MmzgK
```

### Format Rules

- **Column 1**: `command_id` - Unique ID starting from 1 (cannot be 0)
- **Column 2**: `command_grapheme` - The actual text command (lowercase recommended)
- **Column 3**: `command_phoneme` - Phonetic representation (generated by G2P tool)

### Command Constraints

- **No mixed languages** (English or Chinese, not both)
- **No Arabic numerals** in commands
- **No special characters** 
- **Lowercase preferred** unless acronyms with specific pronunciation
- **Multiple commands per ID** supported (separate with commas)

## ðŸ”„ Phonetic Generation Workflow

### 1. Prepare Your Commands

Create a text list of commands you want to recognize:

```bash
# Example commands
turn on light
turn off light
play music
stop music
increase volume
decrease volume
set timer
cancel timer
```

### 2. Generate Phonetic Representations

Use the included `multinet_g2p.py` tool:

```bash
# Single command conversion
python3 multinet_g2p.py --text "turn on light"

# Output:
# in: turn on light
# out: TkN eN Lim
```

### 3. Batch Processing Commands

For multiple commands, use the semicolon separator:

```bash
python3 multinet_g2p.py --text "turn on light;turn off light;play music"

# Output:
# in: turn on light;turn off light;play music  
# out: TkN eN Lim;TkN eF Lim;PLf MmzgK
```

### 4. Create Command File

Format the results into `multinet_model/fst/commands_en.txt`:

```csv
# command_id,command_grapheme,command_phoneme
1,turn on light,TkN eN Lim
2,turn off light,TkN eF Lim
3,play music,PLf MmzgK
4,stop music,STep MmzgK
5,increase volume,gNKRf VeLom
6,decrease volume,DfKRf VeLom
```

## ðŸŽ¨ Advanced Usage

### Multiple Commands per ID

You can assign the same command ID to similar phrases:

```csv
# command_id,command_grapheme,command_phoneme
1,turn on light;switch on light,TkN eN Lim;SMgp eN Lim
2,turn off light;switch off light,TkN eF Lim;SMgp eF Lim
```

### Command Categories

Organize commands by function:

```csv
# Lighting commands (IDs 1-10)
1,turn on light,TkN eN Lim
2,turn off light,TkN eF Lim
3,dim light,Dgm Lim

# Music commands (IDs 11-20)  
11,play music,PLf MmzgK
12,stop music,STep MmzgK
13,next song,NfKST Sel

# Timer commands (IDs 21-30)
21,set timer,SfT TimkR
22,cancel timer,KaNSL TimkR
```

## ðŸ”¨ Build Process

### 1. Prepare Model Target

```bash
cd model

# Copy base models
cp -r multinet_model/mn6_en target/
cp -r multinet_model/fst target/
cp -r vadnet_model/vadnet1_medium target/
```

### 2. Update Commands

Edit `target/fst/commands_en.txt` with your custom commands:

```bash
# Edit the command file
nano target/fst/commands_en.txt
```

### 3. Pack Models

```bash
# Pack all models including custom commands
python3 pack_model.py -m target -o srmodels.bin
```

### 4. Flash to ESP32

```bash
# Flash to model partition (ESP32-S3 16MB)
esptool.py --chip esp32s3 --port /dev/ttyUSB0 --baud 2000000 \
    --before default_reset --after hard_reset \
    write_flash 0x710000 srmodels.bin
```

## ðŸ§ª Testing Commands

### Verify Phonetic Conversion

Test individual commands before building:

```bash
# Test common words
python3 multinet_g2p.py --text "hello world"
python3 multinet_g2p.py --text "computer please help"
python3 multinet_g2p.py --text "artificial intelligence"
```

### Audio Requirements

- **Sample Rate**: 16 kHz
- **Bit Depth**: 16-bit
- **Channels**: Mono
- **Format**: PCM
- **Latency**: <500ms recognition

### Recognition Testing

After flashing, test commands via serial monitor:

```cpp
// In your ESP32 code, check recognition results
esp_mn_results_t *mn_result = multinet->get_results(model_data);
if (mn_result->num > 0) {
    printf("Command ID: %d, Probability: %.2f\n", 
           mn_result->phrase_id[0], mn_result->prob[0]);
}
```

## ðŸŽ¯ Best Practices

### Command Design

1. **Use clear, distinct commands** - Avoid similar-sounding phrases
2. **Keep commands short** - 2-4 words work best
3. **Use common words** - Better phonetic accuracy
4. **Test phonetic output** - Verify G2P conversion makes sense
5. **Group related commands** - Use ID ranges for categories

### Phonetic Optimization

1. **Review G2P output** - Manual verification improves accuracy
2. **Test edge cases** - Proper nouns, technical terms
3. **Consider pronunciation variations** - Multiple phonetic representations
4. **Validate alphabet mapping** - Ensure all phonemes are supported

### Model Performance

1. **Limit command count** - More commands = lower accuracy
2. **Balance vocabulary** - Mix short and long commands
3. **Test with background noise** - Real-world conditions
4. **Monitor memory usage** - ESP32 has limited resources

## ðŸ”§ Troubleshooting

### Common Issues

#### G2P Conversion Errors
```bash
# Error: "skip X, not found in alphabet"
# Solution: Check if phoneme is in the alphabet mapping
```

#### Command Not Recognized
- Verify phonetic representation matches pronunciation
- Check command ID is unique and > 0
- Ensure no special characters in command text
- Test with clear pronunciation

#### Model Loading Failed
- Verify `commands_en.txt` format is correct
- Check file encoding (should be UTF-8)
- Ensure FST files are properly included in target

#### Memory Issues
- Reduce number of commands
- Use shorter command phrases
- Consider MultiNet6 for simpler requirements

### Debug Commands

```bash
# Check model info
cat target/mn6_en/_MODEL_INFO_

# Verify command file format
head -10 target/fst/commands_en.txt

# Check phonetic alphabet coverage
python3 multinet_g2p.py --text "your test phrase here"
```

## ðŸ“Š Example Command Sets

### Home Automation
```csv
# command_id,command_grapheme,command_phoneme
1,turn on lights,TkN eN Lims
2,turn off lights,TkN eF Lims
3,dim lights,Dgm Lims
4,bright lights,BRim Lims
5,lock door,LeK DeR
6,unlock door,cNLeK DeR
7,set temperature,SfT TfMPRpR
8,open blinds,bPN BLiNDS
9,close blinds,KLbS BLiNDS
10,start vacuum,STRT VaKom
```

### Media Control
```csv
# command_id,command_grapheme,command_phoneme
11,play music,PLf MmzgK
12,pause music,PeS MmzgK
13,stop music,STep MmzgK
14,next song,NfKST Sel
15,previous song,PRfVms Sel
16,volume up,VeLom cP
17,volume down,VeLom DmN
18,mute audio,MmT eDfb
19,unmute audio,cNMmT eDfb
20,shuffle playlist,ScFL PLfLgST
```

### System Control
```csv
# command_id,command_grapheme,command_phoneme
21,restart system,RfSTRT SgSTm
22,shutdown system,ScTDmN SgSTm
23,status report,STfTcS RfPeRT
24,check battery,pfK BaTRf
25,wifi status,MiFi STfTcS
26,bluetooth on,BLmTv eN
27,bluetooth off,BLmTv eF
28,sleep mode,SLfP MbD
29,wake up,MfK cP
30,factory reset,FaKTRf RfSfT
```

## ðŸ”— Integration with Project

This guide integrates with your ESP32 WakeWord project structure:

- **Build System**: Use with `pack_model.py` and PlatformIO build process
- **Audio Pipeline**: Works with I2S microphone input at 16kHz
- **Display Feedback**: Command recognition triggers face animations
- **Event System**: Commands processed through FreeRTOS notification system

### ESP32 Code Integration

```cpp
// In your callback handler
void sr_event_callback(sr_event_t event, int command_id) {
    switch (command_id) {
        case 1: // "turn on light"
            digitalWrite(LED_PIN, HIGH);
            notification->send(NOTIFICATION_DISPLAY, EVENT_DISPLAY_SUCCESS);
            break;
        case 2: // "turn off light"  
            digitalWrite(LED_PIN, LOW);
            notification->send(NOTIFICATION_DISPLAY, EVENT_DISPLAY_SUCCESS);
            break;
        // ... more commands
    }
}
```

---

*For more information, see the [ESP-SR Documentation](https://docs.espressif.com/projects/esp-sr/en/latest/esp32/speech_command_recognition/README.html) and the main [Model README](README.md).*
